# -*- coding: utf-8 -*-
"""
Created on Wed Oct 23 21:03:25 2019

@author: mhrahman
"""

import numpy as np
import torch
import torch.nn as nn
from torch.autograd import Variable



class Conv1D (object):
    def __init__(self, in_channel, out_channel,kernel_size,stride):
        self.in_channel = in_channel
        self.out_channel = out_channel
        self.kernel_size = kernel_size
        self.stride = stride
        self.k = np.sqrt(1/(self.in_channel*self.kernel_size))
        self.weight = np.random.uniform(-self.k,self.k,size =(self.out_channel,self.in_channel,self.kernel_size) )        
        self.bias = np.random.uniform(-self.k,self.k,size=self.out_channel)
        
    def __call__(self,X):
        self.X = X.shape[2]
        self.out_size = (np.floor(self.X-self.kernel_size)/self.stride).astype(int) + 1
        self.batch = X.shape[0]
        self.output = np.zeros(shape=[self.batch,self.out_channel,self.out_size])
        
        for i in range(self.batch):
            for j in range(self.out_size):
                k = j*self.stride + self.kernel_size
                z = X[i,:,j*self.stride:k]
                X_rep = np.broadcast_to(z,(self.out_channel,) + z.shape)
                self.output[i,:,j] = np.sum(np.sum(X_rep * self.weight,axis = -1),axis=-1) + self.bias
        return self.output
    def backward(self,delta,X = None):
        self.db = np.zeros(shape=[self.out_channel])
        for i in range(self.batch):
            for j in range(self.out_size):
                self.db += delta[i,:,j]
        self.dw = np.zeros_like(self.weight)
        for n in range(self.batch):
            for f in range(self.out_channel):
                for i in range(self.kernel_size):
                    for k in range(self.out_size):
                        for c in range(self.in_channel):
                            self.dw[f,c,i] += X[n,c,self.stride * k + i] * delta[n,f,k]
                            
            

np.random.seed(10)
net1 = Conv1D(8, 12, 3, 2) ## Your own convolution
net2 = torch.nn.Conv1d(8, 12, 3, 2) ## generated by torch
## initialize the inputs
x1 = np.random.rand(3, 8, 20)
x2 = Variable(torch.tensor(x1),requires_grad=True)
## Copy the parameters from the Conv1D class to PyTorch layer
net2.weight = nn.Parameter(torch.tensor(net1.weight))
net2.bias = nn.Parameter(torch.tensor(net1.bias))
## Your forward and backward
y1 = net1(x1)
b, c, w = y1.shape
delta = np.random.randn(b,c,w)
net1.backward(delta,x1)
## PyTorch forward and backward
y2 = net2(x2)
delta = torch.tensor(delta)
y2.backward(delta)

def comapre (x,y):
    y = y.detach().numpy()
    res = abs(x-y)
    total = np.sum(res)
    return total
    
print(comapre(net1.dw,net2.weight.grad))







#res = abs(y2-y1)
#print(np.sum(res))
#print(net1.weight)